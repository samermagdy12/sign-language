{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "50ef7f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ain: augmenting 28 images...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from albumentations.augmentations.transforms import *\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from mediapipe import solutions\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "folder_path = r\"D:\\original_data_set\\ARSL-No-BackGround-V2\"\n",
    "target_count = 500\n",
    "image_size = (224, 224)\n",
    "\n",
    "mp_hands = solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=True, max_num_hands=1)\n",
    "\n",
    "# Define augmentation pipeline\n",
    "augment = A.Compose([\n",
    "    A.Rotate(limit=20, p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.3),\n",
    "    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
    "    A.RGBShift(p=0.2),\n",
    "    A.MotionBlur(p=0.1),\n",
    "])\n",
    "\n",
    "for class_name in os.listdir(folder_path):\n",
    "    class_dir = os.path.join(folder_path, class_name)\n",
    "    if not os.path.isdir(class_dir):\n",
    "        continue\n",
    "\n",
    "    images = [f for f in os.listdir(class_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    current_count = len(images)\n",
    "\n",
    "    if current_count >= target_count:\n",
    "        continue\n",
    "    else:\n",
    "        needed = target_count - current_count\n",
    "        print(f\"{class_name}: augmenting {needed} images...\")\n",
    "\n",
    "    i = 0\n",
    "    for img_name in images:\n",
    "        img_path = os.path.join(class_dir, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        results = hands.process(img_rgb)\n",
    "        if not results.multi_hand_landmarks:\n",
    "            continue  # Skip if no hand detected\n",
    "\n",
    "        for _ in range(5):  \n",
    "            augmented = augment(image=img_rgb)\n",
    "            aug_img = augmented['image']\n",
    "            aug_img_bgr = cv2.cvtColor(aug_img, cv2.COLOR_RGB2BGR)\n",
    "            save_path = os.path.join(class_dir, f\"aug_{i}_{img_name}\")\n",
    "            cv2.imwrite(save_path, aug_img_bgr)\n",
    "            i += 1\n",
    "\n",
    "            if i >= needed:\n",
    "                break\n",
    "        if i >= needed:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a91db6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Al\\Al_225.jpeg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Al\\Al_195.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Al\\Al_178.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Al\\Al_28.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Al\\Al_148.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Al\\Al_198.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Al\\Al_271.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Alef\\Alef_65.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Alef\\Alef_133.jpeg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Alef\\Alef_174.jpeg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Alef\\Alef_51.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Alef\\Alef_81.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Alef\\Alef_231.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Alef\\Alef_126.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Alef\\Alef_279.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Alef\\Alef_252.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Alef\\Alef_247.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Alef\\Alef_13.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Alef\\Alef_18.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Alef\\Alef_281.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Beh\\Beh_154.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Beh\\Beh_196.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Beh\\Beh_152.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Beh\\Beh_170.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Beh\\Beh_67.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Beh\\Beh_252.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Beh\\Beh_39.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Beh\\Beh_30.jpeg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Beh\\Beh_24.jpeg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Beh\\Beh_55.jpeg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Beh\\Beh_54.jpeg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Beh\\Beh_193.jpeg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Beh\\Beh_71.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Beh\\Beh_207.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Beh\\Beh_203.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Beh\\Beh_92.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Beh\\Beh_175.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Beh\\Beh_232.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Beh\\Beh_288.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Beh\\Beh_21.jpeg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Beh\\Beh_8.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Beh\\Beh_83.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Beh\\Beh_126.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Beh\\Beh_2.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Beh\\Beh_99.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Beh\\Beh_72.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Beh\\Beh_285.jpeg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Beh\\Beh_27.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Beh\\Beh_153.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Beh\\Beh_195.jpeg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Beh\\Beh_180.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Kaf\\Kaf_28.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Kaf\\Kaf_8.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Kaf\\Kaf_70.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Kaf\\Kaf_182.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Kaf\\Kaf_109.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Kaf\\Kaf_130.jpeg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Kaf\\Kaf_256.jpeg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Seen\\Seen_18.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Seen\\Seen_125.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Seen\\Seen_28.jpeg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Seen\\Seen_168.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Sheen\\Sheen_96.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Sheen\\Sheen_38.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Sheen\\Sheen_56.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Sheen\\Sheen_94.jpeg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Sheen\\Sheen_255.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Sheen\\Sheen_107.jpeg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Sheen\\Sheen_40.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Sheen\\Sheen_181.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Sheen\\Sheen_219.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Sheen\\Sheen_1.jpeg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Sheen\\Sheen_115.jpeg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Sheen\\Sheen_151.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Sheen\\Sheen_204.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Teh\\Teh_132.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Teh\\Teh_48.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Teh\\Teh_0.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Teh\\Teh_185.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Teh\\Teh_161.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Teh\\Teh_240.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Teh\\Teh_33.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Teh\\Teh_177.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Teh\\Teh_188.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Teh\\Teh_116.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Teh\\Teh_134.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Teh\\Teh_234.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Teh\\Teh_167.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Teh\\Teh_66.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Teh\\Teh_53.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Teh\\Teh_165.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Teh\\Teh_298.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Teh\\Teh_109.jpeg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Teh\\Teh_249.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Teh\\Teh_38.jpeg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Teh\\Teh_182.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Theh\\Theh_128.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Theh\\Theh_112.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Theh\\Theh_208.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Theh\\Theh_214.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Theh\\Theh_289.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Theh\\Theh_13.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Theh\\Theh_285.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Theh\\Theh_63.jpeg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Theh\\Theh_160.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Theh\\Theh_198.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Theh\\Theh_54.jpg\n",
      "Removed D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\\Theh\\Theh_265.jpg\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "folder_path_2 = r\"D:\\arabic_dataset_for_pre\\ARSL-No-BackGround-V2\"\n",
    "\n",
    "target = 250\n",
    "\n",
    "for class_name in os.listdir(folder_path_2):\n",
    "    class_dir = os.path.join(folder_path_2, class_name)\n",
    "    if not os.path.isdir(class_dir):\n",
    "        continue\n",
    "        \n",
    "    images = []\n",
    "    for img_name in os.listdir(class_dir):\n",
    "        if img_name.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            images.append(os.path.join(class_dir, img_name))\n",
    "    if len(images) > target:\n",
    "        images_to_remove = random.sample(images, len(images) - target)\n",
    "        for img_path in images_to_remove:\n",
    "            os.remove(img_path)\n",
    "            print(f\"Removed {img_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9642cee0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageDataGenerator\n\u001b[0;32m      3\u001b[0m img_size \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)  \n\u001b[0;32m      4\u001b[0m data_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124moriginal_data_set\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mARSL-No-BackGround-V2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Samer\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\_tf_keras\\keras\\__init__.py:29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m visualization\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m wrappers\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m losses\n",
      "File \u001b[1;32mc:\\Users\\Samer\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\_tf_keras\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tf_keras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n",
      "File \u001b[1;32mc:\\Users\\Samer\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\_tf_keras\\keras\\__init__.py:29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m visualization\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m wrappers\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m losses\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:995\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1091\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1190\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "img_size = (224, 224)  \n",
    "data_dir = r\"D:\\original_data_set\\ARSL-No-BackGround-V2\"\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2  # Set aside 20% for validation\n",
    ")\n",
    "\n",
    "train_data = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle =True\n",
    ")\n",
    "\n",
    "val_data = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle =False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ef5cf9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Samer\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 23\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential([\n\u001b[0;32m      5\u001b[0m     Conv2D(\u001b[38;5;241m32\u001b[39m, (\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m3\u001b[39m), padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m      6\u001b[0m     BatchNormalization(),\n\u001b[0;32m      7\u001b[0m     MaxPooling2D(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m),\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Dropout(0.2),\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \n\u001b[0;32m     10\u001b[0m     Conv2D(\u001b[38;5;241m64\u001b[39m, (\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     11\u001b[0m     BatchNormalization(),\n\u001b[0;32m     12\u001b[0m     MaxPooling2D(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m),\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# Dropout(0.2),\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \n\u001b[0;32m     15\u001b[0m     Conv2D(\u001b[38;5;241m128\u001b[39m, (\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     16\u001b[0m     BatchNormalization(),\n\u001b[0;32m     17\u001b[0m     MaxPooling2D(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m),\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# Dropout(0.2),\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \n\u001b[0;32m     20\u001b[0m     GlobalAveragePooling2D(),\n\u001b[0;32m     21\u001b[0m     Dense(\u001b[38;5;241m256\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     22\u001b[0m     Dropout(\u001b[38;5;241m0.5\u001b[39m),\n\u001b[1;32m---> 23\u001b[0m     Dense(\u001b[43mtrain_data\u001b[49m\u001b[38;5;241m.\u001b[39mnum_classes, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[0;32m     24\u001b[0m ])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(224, 224, 3), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2,2),\n",
    "    # Dropout(0.2),\n",
    "\n",
    "    Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2,2),\n",
    "    # Dropout(0.2),\n",
    "\n",
    "    Conv2D(128, (3,3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2,2),\n",
    "    # Dropout(0.2),\n",
    "\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(train_data.num_classes, activation='softmax') \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a66dcc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1017s\u001b[0m 3s/step - accuracy: 0.2851 - loss: 2.2622 - val_accuracy: 0.3636 - val_loss: 1.9367 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1016s\u001b[0m 3s/step - accuracy: 0.3968 - loss: 1.8722 - val_accuracy: 0.4043 - val_loss: 1.7991 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1018s\u001b[0m 3s/step - accuracy: 0.5049 - loss: 1.5066 - val_accuracy: 0.5100 - val_loss: 1.5151 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1012s\u001b[0m 3s/step - accuracy: 0.6053 - loss: 1.2216 - val_accuracy: 0.5806 - val_loss: 1.2591 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1024s\u001b[0m 3s/step - accuracy: 0.6661 - loss: 1.0184 - val_accuracy: 0.6193 - val_loss: 1.1473 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1020s\u001b[0m 3s/step - accuracy: 0.7239 - loss: 0.8524 - val_accuracy: 0.5113 - val_loss: 1.4959 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1018s\u001b[0m 3s/step - accuracy: 0.7606 - loss: 0.7316 - val_accuracy: 0.7257 - val_loss: 0.8235 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1026s\u001b[0m 3s/step - accuracy: 0.7839 - loss: 0.6588 - val_accuracy: 0.7295 - val_loss: 0.7888 - learning_rate: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1024s\u001b[0m 3s/step - accuracy: 0.8028 - loss: 0.5986 - val_accuracy: 0.6570 - val_loss: 1.0231 - learning_rate: 0.0010\n",
      "Epoch 10/30\n",
      "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1022s\u001b[0m 3s/step - accuracy: 0.8271 - loss: 0.5218 - val_accuracy: 0.7395 - val_loss: 0.8231 - learning_rate: 0.0010\n",
      "Epoch 11/30\n",
      "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1019s\u001b[0m 3s/step - accuracy: 0.8359 - loss: 0.4948 - val_accuracy: 0.6235 - val_loss: 1.1617 - learning_rate: 0.0010\n",
      "Epoch 12/30\n",
      "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1006s\u001b[0m 3s/step - accuracy: 0.8466 - loss: 0.4550 - val_accuracy: 0.7108 - val_loss: 0.9454 - learning_rate: 0.0010\n",
      "Epoch 13/30\n",
      "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1032s\u001b[0m 3s/step - accuracy: 0.8890 - loss: 0.3529 - val_accuracy: 0.8217 - val_loss: 0.5368 - learning_rate: 2.0000e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m940s\u001b[0m 2s/step - accuracy: 0.9029 - loss: 0.3078 - val_accuracy: 0.8378 - val_loss: 0.5056 - learning_rate: 2.0000e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m948s\u001b[0m 2s/step - accuracy: 0.9041 - loss: 0.2946 - val_accuracy: 0.7566 - val_loss: 0.7508 - learning_rate: 2.0000e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m943s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.2839 - val_accuracy: 0.8378 - val_loss: 0.4832 - learning_rate: 2.0000e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m941s\u001b[0m 2s/step - accuracy: 0.9260 - loss: 0.2511 - val_accuracy: 0.8501 - val_loss: 0.4744 - learning_rate: 2.0000e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m936s\u001b[0m 2s/step - accuracy: 0.9205 - loss: 0.2456 - val_accuracy: 0.8298 - val_loss: 0.5122 - learning_rate: 2.0000e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m935s\u001b[0m 2s/step - accuracy: 0.9221 - loss: 0.2448 - val_accuracy: 0.8514 - val_loss: 0.4629 - learning_rate: 2.0000e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m943s\u001b[0m 2s/step - accuracy: 0.9269 - loss: 0.2441 - val_accuracy: 0.8436 - val_loss: 0.4808 - learning_rate: 2.0000e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m937s\u001b[0m 2s/step - accuracy: 0.9289 - loss: 0.2146 - val_accuracy: 0.8466 - val_loss: 0.4739 - learning_rate: 2.0000e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m939s\u001b[0m 2s/step - accuracy: 0.9356 - loss: 0.2106 - val_accuracy: 0.8501 - val_loss: 0.4912 - learning_rate: 2.0000e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m943s\u001b[0m 2s/step - accuracy: 0.9336 - loss: 0.2088 - val_accuracy: 0.8556 - val_loss: 0.4663 - learning_rate: 2.0000e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m941s\u001b[0m 2s/step - accuracy: 0.9415 - loss: 0.1918 - val_accuracy: 0.8594 - val_loss: 0.4508 - learning_rate: 4.0000e-05\n",
      "Epoch 25/30\n",
      "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m948s\u001b[0m 2s/step - accuracy: 0.9444 - loss: 0.1882 - val_accuracy: 0.8643 - val_loss: 0.4356 - learning_rate: 4.0000e-05\n",
      "Epoch 26/30\n",
      "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m925s\u001b[0m 2s/step - accuracy: 0.9475 - loss: 0.1754 - val_accuracy: 0.8623 - val_loss: 0.4396 - learning_rate: 4.0000e-05\n",
      "Epoch 27/30\n",
      "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m922s\u001b[0m 2s/step - accuracy: 0.9482 - loss: 0.1759 - val_accuracy: 0.8614 - val_loss: 0.4369 - learning_rate: 4.0000e-05\n",
      "Epoch 28/30\n",
      "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m925s\u001b[0m 2s/step - accuracy: 0.9468 - loss: 0.1742 - val_accuracy: 0.8594 - val_loss: 0.4381 - learning_rate: 4.0000e-05\n",
      "Epoch 29/30\n",
      "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m930s\u001b[0m 2s/step - accuracy: 0.9460 - loss: 0.1725 - val_accuracy: 0.8565 - val_loss: 0.4543 - learning_rate: 4.0000e-05\n",
      "Epoch 30/30\n",
      "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m923s\u001b[0m 2s/step - accuracy: 0.9469 - loss: 0.1718 - val_accuracy: 0.8598 - val_loss: 0.4382 - learning_rate: 8.0000e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e8982900e0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_accuracy',   \n",
    "    patience=7,               \n",
    "    restore_best_weights=True      \n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=4,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_data, validation_data=val_data, epochs=30, callbacks=[early_stop, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecccde42",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124moriginal_data_set\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mARSL-No-BackGround-V2\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmodel.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save(r\"D:\\original_data_set\\ARSL-No-BackGround-V2\\model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
